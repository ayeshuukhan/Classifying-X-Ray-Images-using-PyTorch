{"cells":[{"source":"import random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torchmetrics import Accuracy, F1Score\n\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1771182685711,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"},"id":"cb1bedee-bcd5-4c80-a5ed-93df89af0295","cell_type":"code","execution_count":11,"outputs":[]},{"source":"import os\nimport zipfile\n\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1771182702042,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"},"id":"dd91680d-cb63-4876-9a51-4ee6bb250c7d","cell_type":"code","execution_count":12,"outputs":[]},{"source":"\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))","metadata":{"executionCancelledAt":null,"executionTime":42,"lastExecutedAt":1771182705557,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"},"id":"0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f","cell_type":"code","execution_count":13,"outputs":[]},{"source":"resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)","metadata":{"executionCancelledAt":null,"executionTime":125,"lastExecutedAt":1771182713271,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"c99cf95b-83f3-49e4-9777-4e70736452d8","cell_type":"code","execution_count":15,"outputs":[]},{"source":"\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 1)","metadata":{"executionCancelledAt":null,"executionTime":9,"lastExecutedAt":1771182715938,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Freeze the parameters of the model\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final layer for binary classification\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 1)"},"id":"7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960","cell_type":"code","execution_count":16,"outputs":[]},{"source":"\ndef train(model, train_loader, criterion, optimizer, num_epochs):\n\n    for epoch in range(num_epochs):\n     \n        model.train()\n\n        running_loss = 0.0\n        running_accuracy = 0\n\n        for inputs, labels in train_loader:\n\n            optimizer.zero_grad()\n      \n            labels = labels.float().unsqueeze(1)\n\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs) > 0.5\n            loss = criterion(outputs, labels)\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            running_accuracy += torch.sum(preds == labels.data)\n\n        train_loss = running_loss / len(train_dataset)\n        train_acc = running_accuracy.double() / len(train_dataset)\n\n        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n              .format(epoch+1, num_epochs, train_loss, train_acc))","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1771182719781,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#------------------------------\n# Q3a: Define the training loop\n#------------------------------\n\n# Model training/fine-tuning loop\ndef train(model, train_loader, criterion, optimizer, num_epochs):\n    \n    # Train the model for the specified number of epochs\n    for epoch in range(num_epochs):\n        # Set the model to train mode\n        model.train()\n\n        # Initialize the running loss and accuracy\n        running_loss = 0.0\n        running_accuracy = 0\n\n        # Iterate over the batches of the train loader\n        for inputs, labels in train_loader:\n\n            # Zero the optimizer gradients\n            optimizer.zero_grad()\n            \n            # Ensure labels have the same dimensions as outputs\n            labels = labels.float().unsqueeze(1)\n\n            # Forward pass\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimizer step\n            loss.backward()\n            optimizer.step()\n\n            # Update the running loss and accuracy\n            running_loss += loss.item() * inputs.size(0)\n            running_accuracy += torch.sum(preds == labels.data)\n\n        # Calculate the train loss and accuracy for the current epoch\n        train_loss = running_loss / len(train_dataset)\n        train_acc = running_accuracy.double() / len(train_dataset)\n\n        # Print the epoch results\n        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n              .format(epoch+1, num_epochs, train_loss, train_acc))"},"cell_type":"code","id":"20eab0e5-0cd2-44a7-be3d-b1787d58f6a4","outputs":[],"execution_count":17},{"source":"\nmodel = resnet18\n\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\ntrain(model, train_loader, criterion, optimizer, num_epochs=20)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":357,"type":"stream"}}},"cell_type":"code","id":"c12960af-8a01-44cd-b2d3-145ca949e533","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [1/20], train loss: 0.7737, train acc: 0.6100\nEpoch [2/20], train loss: 0.4974, train acc: 0.7600\nEpoch [3/20], train loss: 0.5371, train acc: 0.6700\nEpoch [4/20], train loss: 0.3306, train acc: 0.8733\nEpoch [5/20], train loss: 0.3732, train acc: 0.8767\nEpoch [6/20], train loss: 0.3056, train acc: 0.8933\nEpoch [7/20], train loss: 0.2479, train acc: 0.9300\nEpoch [8/20], train loss: 0.2980, train acc: 0.8667\nEpoch [9/20], train loss: 0.2370, train acc: 0.9067\nEpoch [10/20], train loss: 0.2185, train acc: 0.9200\nEpoch [11/20], train loss: 0.2396, train acc: 0.9200\nEpoch [12/20], train loss: 0.2141, train acc: 0.9200\nEpoch [13/20], train loss: 0.1916, train acc: 0.9200\nEpoch [14/20], train loss: 0.2048, train acc: 0.9133\nEpoch [15/20], train loss: 0.1980, train acc: 0.9167\nEpoch [16/20], train loss: 0.1765, train acc: 0.9300\nEpoch [17/20], train loss: 0.1869, train acc: 0.9300\nEpoch [18/20], train loss: 0.1776, train acc: 0.9333\nEpoch [19/20], train loss: 0.1767, train acc: 0.9400\nEpoch [20/20], train loss: 0.1607, train acc: 0.9400\n"}],"execution_count":24},{"source":"\nmodel = resnet18\nmodel.eval()\n\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad(): \n  for inputs, labels in test_loader:\n\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  \n\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    all_preds = torch.tensor(all_preds)\n    \n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()\n \nprint(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n","metadata":{"executionCancelledAt":null,"executionTime":1916,"lastExecutedAt":1771183151364,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n#-----------------------\n# Evaluation code\n#----------------------- \n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  # Disable gradient calculation for evaluation\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()\n \nprint(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"c6087401-1781-4b3a-b1fa-55bb52a87dd3","outputs":[{"output_type":"stream","name":"stdout","text":"\nTest accuracy: 0.660\nTest F1-score: 0.746\n"}],"execution_count":25},{"source":"torch.save(model.state_dict(), \"chest_xray_resnet18.pth\")\n","metadata":{"executionCancelledAt":null,"executionTime":367,"lastExecutedAt":1771183160672,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"torch.save(model.state_dict(), \"chest_xray_resnet18.pth\")\n"},"cell_type":"code","id":"e71298cd-bd67-408a-8e8d-c5ed434071d3","outputs":[],"execution_count":26},{"source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\n\nmodel = models.resnet18(weights=None)\n\nmodel.fc = nn.Linear(model.fc.in_features, 1)\n\nmodel.load_state_dict(torch.load(\"chest_xray_resnet18.pth\", map_location=torch.device('cpu')))\n\nmodel.eval()\n\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std = [0.229, 0.224, 0.225]\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),   \n    transforms.ToTensor(),\n    transforms.Normalize(mean=transform_mean, std=transform_std)\n])\n\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\n\ndef predict_image(image_path):\n\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0)  \n\n    with torch.no_grad():\n        output = model(image)\n        prob = torch.sigmoid(output).item()\n\n    prediction = classes[1] if prob > 0.5 else classes[0]\n\n    print(f\"Prediction: {prediction}\")\n    print(f\"Probability of Pneumonia: {prob:.4f}\")\n\n\npredict_image(\"xrayyy.jpg\")   \n","metadata":{"executionCancelledAt":null,"executionTime":403,"lastExecutedAt":1771183163203,"lastExecutedByKernel":"e514e742-1baf-4b62-b101-1f514ce42923","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\n\nmodel = models.resnet18(weights=None)\n\nmodel.fc = nn.Linear(model.fc.in_features, 1)\n\nmodel.load_state_dict(torch.load(\"chest_xray_resnet18.pth\", map_location=torch.device('cpu')))\n\nmodel.eval()\n\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std = [0.229, 0.224, 0.225]\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),   \n    transforms.ToTensor(),\n    transforms.Normalize(mean=transform_mean, std=transform_std)\n])\n\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\n\ndef predict_image(image_path):\n\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0)  \n\n    with torch.no_grad():\n        output = model(image)\n        prob = torch.sigmoid(output).item()\n\n    prediction = classes[1] if prob > 0.5 else classes[0]\n\n    print(f\"Prediction: {prediction}\")\n    print(f\"Probability of Pneumonia: {prob:.4f}\")\n\n\npredict_image(\"xrayyy.jpg\")   \n","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"9c94c880-3bce-44dc-b903-2cc10d5bbece","outputs":[{"output_type":"stream","name":"stdout","text":"Prediction: PNEUMONIA\nProbability of Pneumonia: 0.9802\n"}],"execution_count":27}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}